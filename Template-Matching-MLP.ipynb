{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f1018e6",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a576c548",
   "metadata": {},
   "source": [
    "# processing and combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cd13fd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16110\n",
      "16110\n",
      "16110\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import itertools\n",
    "from itertools import combinations\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "import skimage\n",
    "import numpy as np\n",
    "from skimage import color\n",
    "from skimage import data, color\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "comb_paths=[]\n",
    "comb_images=[]\n",
    "label=[]\n",
    "#flatten_list=[]\n",
    "\n",
    "for address, dirs, files in os.walk('C:/Users/computer Market/deep learning tasks/assignment2dataset/Dataset/training'):\n",
    "    for name in files:\n",
    "        comb_paths.append(os.path.join(address,name))\n",
    "        img=cv2.imread(os.path.join(address,name))\n",
    "        img_resized = resize( img , (32 ,32, 3 ))\n",
    "        img_gray=color.rgb2gray( img_resized  )\n",
    "        #img_reshape = img_gray.reshape((3072))\n",
    "        #flatten_list.append(img_reshape)\n",
    "        #result=np.round(img_gray*255)\n",
    "        comb_images.append(img_gray) \n",
    "path_pair=list(itertools.combinations(comb_paths,2))\n",
    "img_pair=list(combinations(comb_images,2))\n",
    "#flatten_pair_list=list(combinations(flatten_list,2))\n",
    "for i in path_pair:\n",
    "    ph1 =os.path.dirname(i[0])\n",
    "    ph2=os.path.dirname(i[1])\n",
    "    if(ph1==ph2):\n",
    "        label.append(1)\n",
    "    else :\n",
    "        label.append(0)\n",
    "print(len(path_pair))        \n",
    "print(len(img_pair))\n",
    "print(len(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b53d80",
   "metadata": {},
   "source": [
    "# matching function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3f1f757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  \n",
    "import pandas as pd \n",
    "def Matching(imgA ,imgb, method='cross-correlation', normalized=False):\n",
    "    #Check if true  ------> normalized\n",
    "    if normalized==True:\n",
    "        sc = StandardScaler()\n",
    "        imgA= pd.DataFrame(sc.fit_transform(imgA))\n",
    "        imgb= pd.DataFrame(sc.fit_transform(imgb))\n",
    "        #imgA=(imgA-np.mean(imgA))/np.std(imgA)\n",
    "        #imgb=(imgb-np.mean(imgb))/np.std(imgb)\n",
    "        #Standardization\n",
    "        # noramlization\n",
    "        #for i in range(256):\n",
    "        #    mn = np.min(ar2)\n",
    "        #    mx = np.max(ar2)\n",
    "        #    norm = (ar2 - mn) * (1.0 / (mx - mn))  \n",
    "        #for i in range(256):\n",
    "         #   mn = np.min(ar1)\n",
    "         #   mx = np.max(ar1)\n",
    "         #   norm = (ar1 - mn) * (1.0 / (mx - mn))\n",
    "        ############another way of normalization\n",
    "        imgA=imgA/255\n",
    "        imgb=imgb/255\n",
    "    if method=='cross-correlation':\n",
    "        c_value=0\n",
    "        for x in range(len(imgA)):\n",
    "            \n",
    "            for y in range(len(imgb[x])):\n",
    "                \n",
    "                c_value+=imgA[x][y]*imgb[x][y]  \n",
    "        return c_value\n",
    "    #print(np.sum(imgA*imgb))\n",
    "    elif method=='convolution':\n",
    "        #fliped_img1=np.flip(np.flip(imgA,axis=0),axis=1)\n",
    "        #fliped_img2=np.flip(np.flip(imgb,axis=0),axis=1)\n",
    "        imgA=np.flip(imgA,axis=0)\n",
    "        imgA=np.flip(imgA,axis=1)\n",
    "        c_value=0\n",
    "        for x in range(len(imgA)):\n",
    "            \n",
    "            for y in range(len(imgb[x])):\n",
    "                \n",
    "                c_value+=imgA[x][y]*imgb[x][y]  \n",
    "        return c_value\n",
    "        #print(np.sum(imgA*imgb))\n",
    "    elif method=='sum_of_square_root':\n",
    "        square=np.square(imgA-imgb)\n",
    "        #print(np.sum(square))\n",
    "        ssd=0\n",
    "        for x in range(len(imgA)):\n",
    "            for y in range(len(imgb)):\n",
    "                ssd +=np.square(imgA[x][y]-imgb[x][y])\n",
    "        return ssd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "539a6a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_value=[]\n",
    "for r in img_pair:\n",
    "    u=Matching(r[0],r[1])\n",
    "    matching_value.append(u)\n",
    "k=np.mean(matching_value)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee229628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13488    12]\n",
      " [ 2598    12]]\n",
      "accuracy 0.8379888268156425\n",
      "precision 0.5\n",
      "recall 0.004597701149425287\n",
      "f1-measure 0.009111617312072893\n"
     ]
    }
   ],
   "source": [
    "thereshold_label=[]\n",
    "for v in img_pair:\n",
    "    e=Matching(v[0],v[1]   )\n",
    "    #print(e)\n",
    "    if e<k:\n",
    "        thereshold_label.append(0)\n",
    "    else:\n",
    "         thereshold_label.append(1)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matrix = confusion_matrix(label,thereshold_label)\n",
    "print(matrix) \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,f1_score\n",
    "acc=accuracy_score(label,thereshold_label)\n",
    "print(\"accuracy\", acc)\n",
    "pre=precision_score(label,thereshold_label)\n",
    "print(\"precision\", pre),\n",
    "rec=recall_score(label,thereshold_label)\n",
    "print(\"recall\",rec )\n",
    "f1= f1_score(label,thereshold_label)\n",
    "print(\"f1-measure\",f1 )\n",
    "#for b in  thereshold_label:\n",
    "#    print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627ba990",
   "metadata": {},
   "source": [
    "# Testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191419d5",
   "metadata": {},
   "source": [
    "# preproccing and combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "19262519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1770\n",
      "1770\n",
      "1770\n"
     ]
    }
   ],
   "source": [
    "comb_paths_test=[]\n",
    "comb_images_test=[]\n",
    "label_test=[]\n",
    "#flatten_list=[]\n",
    "for address, dirs, files in os.walk('C:/Users/computer Market/deep learning tasks/assignment2dataset/Dataset/testing'):\n",
    "    for name in files:\n",
    "        comb_paths_test.append(os.path.join(address,name))\n",
    "        img1=cv2.imread(os.path.join(address,name))\n",
    "        img_resized1= resize( img1 , (32 ,32, 3 ))\n",
    "        img_gray1=color.rgb2gray( img_resized1  )\n",
    "        comb_images_test.append(img_gray1) \n",
    "path_pair_test=list(combinations(comb_paths_test,2))\n",
    "#for t in path_pair_test:\n",
    "#    w=np.array(t)\n",
    "#    print(w.shape)\n",
    "img_pair_test=list(combinations(comb_images_test,2))\n",
    "for i in path_pair_test:\n",
    "    ph11 =os.path.dirname(i[0])\n",
    "    ph21=os.path.dirname(i[1])\n",
    "    if(ph11==ph21):\n",
    "        label_test.append(1)\n",
    "    else :\n",
    "        label_test.append(0)     \n",
    "print(len(img_pair_test))\n",
    "print(len(label_test))\n",
    "print(len(path_pair_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f97ac706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1499    1]\n",
      " [ 268    2]]\n",
      "accuracy 0.8480225988700565\n",
      "precision 0.6666666666666666\n",
      "recall 0.007407407407407408\n",
      "f1-measure 0.014652014652014652\n",
      "1.0623753070831299\n"
     ]
    }
   ],
   "source": [
    "thereshold_label_test=[]\n",
    "import time\n",
    "start_time=time.time()\n",
    "for v in img_pair_test:\n",
    "    e=Matching(v[0],v[1])\n",
    "    #print(e)\n",
    "    if e<k:\n",
    "        thereshold_label_test.append(0)\n",
    "    else:\n",
    "         thereshold_label_test.append(1)\n",
    "end_time=time.time()\n",
    "from sklearn.metrics import confusion_matrix\n",
    "matrix_test = confusion_matrix(label_test,thereshold_label_test)\n",
    "print(matrix_test) \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,f1_score\n",
    "acc_test=accuracy_score(label_test,thereshold_label_test)\n",
    "print(\"accuracy\", acc_test)\n",
    "pre_test=precision_score(label_test,thereshold_label_test)\n",
    "print(\"precision\", pre_test),\n",
    "rec_test=recall_score(label_test,thereshold_label_test)\n",
    "print(\"recall\",rec_test )\n",
    "f1_test= f1_score(label_test,thereshold_label_test)\n",
    "print(\"f1-measure\",f1_test )\n",
    "print(end_time-start_time)\n",
    "#for b in  thereshold_label:\n",
    "#    print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf64565",
   "metadata": {},
   "source": [
    "# Mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bddbeb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Computer Market\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc\n",
      "0.5474576271186441\n",
      "0.9625077591558039\n",
      "pre\n",
      "0.16519546027742749\n",
      "0.9911851126346719\n",
      "rec\n",
      "0.48518518518518516\n",
      "0.7754789272030651\n",
      "f1\n",
      "0.2464722483537159\n",
      "0.8701633705932932\n",
      "time\n",
      "3.5963869094848633\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "flatten_image=[]\n",
    "flatten_image_test=[]\n",
    "for d in img_pair:\n",
    "    fla1=np.array(d)\n",
    "    flatten1=fla1.flatten()    \n",
    "    flatten_image.append(flatten1) \n",
    "for q in img_pair_test:\n",
    "    fla11_test=np.array(q)\n",
    "    flatten11=fla11_test.flatten()    \n",
    "    flatten_image_test.append(flatten11) \n",
    "start_time_test=time.time()\n",
    "\n",
    "Logistic_model = LogisticRegression()\n",
    "Logistic_model = Logistic_model.fit(  flatten_image , label)\n",
    "predicit_y_train=Logistic_model.predict(flatten_image)\n",
    "predicit_y_test=Logistic_model.predict(flatten_image_test)\n",
    "end_time_test=time.time()\n",
    "print(\"acc\")\n",
    "print( accuracy_score(   label_test ,  predicit_y_test )  )\n",
    "print( accuracy_score(   label ,  predicit_y_train )  )\n",
    "############precision\n",
    "print(\"pre\")\n",
    "print( precision_score(   label_test ,  predicit_y_test )  )\n",
    "print( precision_score(   label ,  predicit_y_train )  )\n",
    "###########recall\n",
    "print(\"rec\")\n",
    "print( recall_score(   label_test ,  predicit_y_test )  )\n",
    "print( recall_score(   label ,  predicit_y_train )  )\n",
    "#############f1\n",
    "print(\"f1\")\n",
    "print( f1_score(   label_test ,  predicit_y_test )  )\n",
    "print( f1_score(   label ,  predicit_y_train )  )\n",
    "print(\"time\")\n",
    "print(end_time_test-start_time_test)\n",
    "#for f in flatten_image:\n",
    "#    print(f.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3704945",
   "metadata": {},
   "source": [
    "# Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ed0fdd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc\n",
      "0.5553672316384181\n",
      "0.9392302917442582\n",
      "pre\n",
      "0.1731984829329962\n",
      "0.9828300769686205\n",
      "rec\n",
      "0.5074074074074074\n",
      "0.6360153256704981\n",
      "f1\n",
      "0.2582469368520264\n",
      "0.7722726215398931\n",
      "time\n",
      "31802.4414396286\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.manifold import Isomap\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "pca = IncrementalPCA(n_components=16)\n",
    "#######train\n",
    "flatten_rd_image=[]\n",
    "flatten_rd_image_test=[]\n",
    "g=[]\n",
    "for t in comb_images :\n",
    "    x= pca.fit_transform(t)\n",
    "    g.append(x)\n",
    "pcaflatten_image=list(combinations(g,2))\n",
    "for e in pcaflatten_image:\n",
    "    fla11=np.array(e)\n",
    "    flatten11=fla11.flatten()    \n",
    "    flatten_rd_image.append(flatten11)  \n",
    "#########test\n",
    "w=[]\n",
    "for t in comb_images_test:\n",
    "    y= pca.fit_transform(t)\n",
    "    w.append(y)\n",
    "pcaflatten_image_test=list(combinations(w,2))\n",
    "for e in pcaflatten_image_test:\n",
    "    fla12=np.array(e)\n",
    "    flatten12=fla12.flatten()    \n",
    "    flatten_rd_image_test.append(flatten12)  \n",
    "######train\n",
    "Logistic_model = LogisticRegression()\n",
    "Logistic_model = Logistic_model.fit( flatten_rd_image, label)\n",
    "predicit_y_train=Logistic_model.predict(flatten_rd_image)\n",
    "predicit_y_test=Logistic_model.predict(flatten_rd_image_test)\n",
    "end_time_test=time.time()\n",
    "print(\"acc\")\n",
    "print( accuracy_score(   label_test ,  predicit_y_test )  )\n",
    "print( accuracy_score(   label ,  predicit_y_train )  )\n",
    "############precision\n",
    "print(\"pre\")\n",
    "print( precision_score(   label_test ,  predicit_y_test )  )\n",
    "print( precision_score(   label ,  predicit_y_train )  )\n",
    "###########recall\n",
    "print(\"rec\")\n",
    "print( recall_score(   label_test ,  predicit_y_test )  )\n",
    "print( recall_score(   label ,  predicit_y_train )  )\n",
    "#############f1\n",
    "print(\"f1\")\n",
    "print( f1_score(   label_test ,  predicit_y_test )  )\n",
    "print( f1_score(   label ,  predicit_y_train )  )\n",
    "print(\"time\")\n",
    "print(end_time_test-start_time_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "89f7f4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16110\n",
      "16110\n"
     ]
    }
   ],
   "source": [
    "print(len(pcaflatten_image))\n",
    "print(len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554c5224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2c89844d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba015315",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
